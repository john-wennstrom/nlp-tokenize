# nlp-tokenize
It opens a text file, turns it into a byte (u8) vector and tokenizes it by spaces and line breaks.
Benchmark has results of 5Mb/s. If someone knows how to increase performance, I value your feedback. =)

Run it like this:
`cargo run -- <FILE>`
